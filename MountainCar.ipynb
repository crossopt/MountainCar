{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "env = gym.make('MountainCar-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, env):\n",
    "        self.min_pos, self.max_pos = env.observation_space.low[0], env.observation_space.high[0]\n",
    "        self.min_vel, self.max_vel = env.observation_space.low[1], env.observation_space.high[1]\n",
    "        self.actions = env.action_space.n\n",
    "\n",
    "        self.prob, self.step_prob = 0.2, 0.0002\n",
    "        self.step_pos, self.step_vel = 10.0, 100.0\n",
    "        board_size = (self.PosIndex(self.max_pos) + 2, self.VelIndex(self.max_vel) + 2, self.actions)\n",
    "        self.board = np.random.uniform(low = -1, high = 1, size = board_size)\n",
    "\n",
    "    def PosIndex(self, pos):\n",
    "        return int((pos - self.min_pos) * self.step_pos)\n",
    "\n",
    "    def VelIndex(self, vel):\n",
    "        return int((vel - self.min_vel) * self.step_vel)\n",
    "\n",
    "    def Move(self, state):\n",
    "        if np.random.uniform() < self.prob:\n",
    "            return np.random.randint(self.actions)\n",
    "        return np.argmax(self.board[self.PosIndex(state[0]), self.VelIndex(state[1])])\n",
    "\n",
    "    def UpdateBoard(self, old_state, new_state, action, reward):\n",
    "        old_pos = self.PosIndex(old_state[0])\n",
    "        old_vel = self.VelIndex(old_state[1])\n",
    "        if new_state[0] >= 0.5:\n",
    "            self.board[old_pos, old_vel, action] = max(0, self.board[old_pos, old_vel, action] + 0.1)\n",
    "        else:\n",
    "            self.board[old_pos, old_vel, action] += 0.15 * (reward +\n",
    "                                 0.9 * np.max(self.board[self.PosIndex(new_state[0]),\n",
    "                                                          self.VelIndex(new_state[1])]) -\n",
    "                                 self.board[old_pos, old_vel, action])\n",
    "\n",
    "    def ReduceRandom(self):\n",
    "        self.prob = max(0, self.prob - self.step_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ResultTracker:\n",
    "    def __init__(self, round_length):\n",
    "        self.counter = 0\n",
    "        self.round_length = round_length\n",
    "        self.results = []\n",
    "        self.extras = []\n",
    "\n",
    "    def AddResult(self, amount):\n",
    "        self.results.append(amount)\n",
    "        if len(self.results) >= self.round_length:\n",
    "            self.counter += 1\n",
    "            # self.PrintResults()\n",
    "            self.results = []\n",
    "\n",
    "    def PrintResults(self):\n",
    "        average = sum(self.results) / len(self.results)\n",
    "        best = max(self.results)\n",
    "        print \"#{}: {} average over {} rounds, best is {}\".format(self.counter,\n",
    "                                                                  average, len(self.results), best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agent = Agent(env)\n",
    "tracker = ResultTracker(100)\n",
    "tries = 10000\n",
    "for i in range(tries):\n",
    "    state = env.reset()\n",
    "    score = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = agent.Move(state)\n",
    "        new_state, reward, done, info = env.step(action)\n",
    "        agent.UpdateBoard(state, new_state, action, reward)\n",
    "        state = new_state\n",
    "        score += reward\n",
    "    tracker.AddResult(score)\n",
    "    agent.ReduceRandom()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Just for fun: compare solution that actually makes an effort to use ML and a greedy agent written in 5 minutes (no physics included)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GreedyAgent:\n",
    "    def Move(self, state):\n",
    "        return 0 if state[1] < 0.01 else 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def GetAverageResult(tries, agent):\n",
    "    amount = 0\n",
    "    for i in range(tries):\n",
    "        state = env.reset()\n",
    "        score = 0\n",
    "        done = False\n",
    "        action = 0\n",
    "        while not done:\n",
    "            action = agent.Move(state)\n",
    "            state, reward, done, info = env.step(action)\n",
    "            score += reward\n",
    "        amount += score\n",
    "    return amount / tries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final results for both Agent and GreedyAgent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average result over 10000 tries for Agent is -146.5849\n",
      "Average result over 10000 tries for GreedyAgent is -158.3322\n"
     ]
    }
   ],
   "source": [
    "print \"Average result over 10000 tries for Agent is {}\".format(GetAverageResult(10000, agent))\n",
    "print \"Average result over 10000 tries for GreedyAgent is {}\".format(GetAverageResult(10000, GreedyAgent()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
